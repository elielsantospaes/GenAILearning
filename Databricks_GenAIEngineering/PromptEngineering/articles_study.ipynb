{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "400df502-9108-455c-ae55-5cd77339cd33",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install necessary libraries"
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow==2.10.1 lxml==4.9.3 langchain==0.1.5 databricks-vectorsearch==0.22 cloudpickle==2.2.1 databricks-sdk==0.18.0 cloudpickle==2.2.1 pydantic==2.5.2 openpyxl\n",
    "%pip install pip mlflow[databricks]==2.10.1 PyPDF2\n",
    "\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa669549-1e32-4b75-a70e-77f7dea81c2f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Imports"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import io\n",
    "import plotly.express as px\n",
    "from langchain_community.chat_models import ChatDatabricks\n",
    "import PyPDF2\n",
    "\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "28aa772a-9e09-483d-babb-fe8f1cfbe391",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Instaciate a chatbot (llama 4 maverik)"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "chat_endpoint = \"databricks-llama-4-maverick\" \n",
    "chat_model = ChatDatabricks(endpoint = chat_endpoint,\n",
    "                            temperature = 0,\n",
    "                            max_tokens = 8192) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e2155ab-92e7-4ee3-9325-73d8678c273a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "path of articles"
    }
   },
   "outputs": [],
   "source": [
    "base_path = \"/Workspace/Users/elielriey@gmail.com/GenAILearning/Databricks_GenAIEngineering/PromptEngineering/papers\"\n",
    "files_list = os.listdir(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9292a0a-bfb8-4994-92a5-1ea6ed275049",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_extraction_prompt(topic, article):\n",
    "\n",
    "    EXTRATION_PROMPT = f\"\"\"\n",
    "    INSTRUCTION:\n",
    "    You will receive a text with some topics and subtopics. You task is to extract only the topic you will be provided in the task:\n",
    "\n",
    "    TASK:\n",
    "    Extract the whole text of the {topic} of the article.\n",
    "\n",
    "    OUTPUT:\n",
    "    Your answer must be only the extracted text. \n",
    "    Do not add any other text or information.\n",
    "    Do not explain what you do.\n",
    "\n",
    "    Following the instrucionts above extract the {topic} of this article: {article}\n",
    "    \"\"\"\n",
    "\n",
    "    return EXTRATION_PROMPT\n",
    "\n",
    "def generate_summarization_prompt(topic): \n",
    "\n",
    "    SUMMARIZE_PROMPT= \"\"\"\n",
    "    INSTRUCTION:  \n",
    "    You are a research assistant specialized in summarizing and analyzing scientific articles. you will be provides of a {topic} of a article. You will analise it in details.\n",
    "\n",
    "    CONTEXT:  \n",
    "    The content of the {topic} are in the context.\n",
    "\n",
    "    INPUT / QUESTION:  \n",
    "    context: {topic}\n",
    "\n",
    "    TASK: \n",
    "    Summarize the text present in the context, bringing the main points presented and the references used to support the points. \n",
    "    \"\"\"\n",
    "\n",
    "    return SUMMARIZE_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85078ff9-221b-4c7e-b0ad-bd223542998f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path):\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        text = \"\"\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "        return text  # Truncate if needed for token limit\n",
    "\n",
    "# def analyze_article(EXTRACTION_PROMPT, SUMMARIZE_PROMPT):\n",
    "#     extraction = chat_model.invoke(EXTRACTION_PROMPT).content\n",
    "#     SUMMARIZE_PROMPT = generate_summarization_prompt(extraction)\n",
    "#     sumarization = chat_model.invoke(SUMMARIZE_PROMPT)\n",
    "            \n",
    "#     return sumarization.content\n",
    "\n",
    "# def main():\n",
    "#     for filename in files_list:\n",
    "        \n",
    "#         if filename.endswith(\".pdf\"):\n",
    "#             path = os.path.join(base_path, filename)\n",
    "#             article_text = extract_text_from_pdf(path)\n",
    "#             for topic in [\"Introduction\"]:#, \"Methods\", \"Results\", \"Discussion\"]:\n",
    "#                 analysis = analyze_article(generate_extraction_prompt(topic, article_text))\n",
    "#                 output_path = path.replace(\".pdf\", \"_analysis.txt\")\n",
    "#                 with open(output_path, \"w\", encoding=\"utf-8\") as out_file:\n",
    "#                     out_file.write(analysis)\n",
    "#                 print(f\"Analysis saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c2142c82-3d63-42fb-847b-3b76d6c1ce46",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "topic = \"Introduction\"\n",
    "print(f\"Analisando o artigo {files_list[0]}\\n\")\n",
    "path = os.path.join(base_path, files_list[0])\n",
    "article = extract_text_from_pdf(path)\n",
    "extraction = chat_model.invoke(generate_extraction_prompt(topic, article)).content\n",
    "extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53ab6d96-90b1-4e21-bc92-b9131b229216",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "articles_study",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
