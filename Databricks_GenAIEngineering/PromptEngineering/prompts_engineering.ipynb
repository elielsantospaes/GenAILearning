{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "426a2e29-b971-4e0b-8069-3e07a46ce056",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install necessary libraries"
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow==2.10.1 lxml==4.9.3 langchain==0.1.5 databricks-vectorsearch==0.22 cloudpickle==2.2.1 databricks-sdk==0.18.0 cloudpickle==2.2.1 pydantic==2.5.2 openpyxl\n",
    "%pip install pip mlflow[databricks]==2.10.1\n",
    "\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a22e6910-7c1d-41ca-9274-749791f1be7a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Imports"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import io\n",
    "import plotly.express as px\n",
    "from langchain_community.chat_models import ChatDatabricks\n",
    "\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fdf206d-8ffd-4cf8-979a-c00edb2f956b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Instaciate a chatbot (llama)"
    }
   },
   "outputs": [],
   "source": [
    "chat_endpoint = \"databricks-llama-4-maverick\" \n",
    "chat_model = ChatDatabricks(endpoint = chat_endpoint,\n",
    "                            temperature = 0,\n",
    "                            max_tokens = 8096) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fcc22fe-0234-4226-80fe-5d77e7761227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Prompt Engineering    \n",
    "**Definitions**    \n",
    "  * **Prompt:** is an input or query given to a LLM to elict to a specific response or output        \n",
    "  * **Prompt Engineering:** is the pratice of designing and refining prompts to optimize the responses generated by AI models.  \n",
    "\n",
    "A good prompt usually consist of:    \n",
    "  * Instruction    \n",
    "  * Context    \n",
    "  * input / question    \n",
    "  * Output type / format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcd58b48-551d-44f7-a956-8c740f649624",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 1.  Zero-shot Prompting.   \n",
    "Prompt for a generation of content, text, video, image etc... without providing any examples or additional training specific task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2214abeb-4f87-4ba1-a9df-ae8fd232ca20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### Examples generated by ChatGPT:   \n",
    "**Prompt one:**   \n",
    "Translate the following sentence to French: ‚ÄúI love learning about artificial intelligence.‚Äù   \n",
    "**LLM's answer one:**   \n",
    "J'aime apprendre l'intelligence artificielle.   \n",
    "\n",
    "**Prompt two:**   \n",
    "Summarize this paragraph in one sentence: ‚ÄúPrompt engineering is the art of crafting inputs to guide large language models to perform useful tasks more effectively.‚Äù   \n",
    "**LLM's answer two:**    \n",
    "Prompt engineering is the practice of designing inputs to improve LLM performance.   \n",
    "\n",
    "**Prompt three:**   \n",
    "Classify the following tweet as positive, negative, or neutral: ‚ÄúThe app keeps crashing after the update.‚Äù\n",
    "**LLM's answer three:**    \n",
    "Negative   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fef47ff0-61f1-461f-a83b-687346619622",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Same cases in Llama 4 maverick"
    }
   },
   "outputs": [],
   "source": [
    "Prompt_one = \"Translate the following sentence to French: ‚ÄúI love learning about artificial intelligence.\"\n",
    "LLM_answer_one = chat_model.invoke(Prompt_one)\n",
    "\n",
    "print(LLM_answer_one.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c110f05c-fc0b-4573-95fc-90c2a0010ad2",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Same cases in Llama 4 maverick"
    }
   },
   "outputs": [],
   "source": [
    "Prompt_two = \"Summarize this paragraph in one sentence: ‚ÄúPrompt engineering is the art of crafting inputs to guide large language models to perform useful tasks more effectively.\"\n",
    "LLM_answer_two = chat_model.invoke(Prompt_two)\n",
    "\n",
    "print(LLM_answer_two.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f3d38dcf-596e-4bb7-98fe-f8687a5cc6f4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Same cases in Llama 4 maverick"
    }
   },
   "outputs": [],
   "source": [
    "Prompt_three = \"Classify the following tweet as positive, negative, or neutral: ‚ÄúThe app keeps crashing after the update.\"\n",
    "LLM_answer_three = chat_model.invoke(Prompt_three)\n",
    "\n",
    "print(LLM_answer_three.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d6b9046-276d-4f34-a8bc-1303294b32e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 2. Few-shot Prompting.    \n",
    "Prompt provides with a few input-ouput examples to guide the model for generating the desired outuput."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6004a590-fc59-45c8-9c42-a90c84f8cef0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Example generated by ChatGPT    \n",
    "**Prompt one:**    \n",
    "Translate English to Spanish:   \n",
    "\n",
    "Hello ‚Üí Hola\n",
    "\n",
    "Good night ‚Üí Buenas noches   \n",
    "\n",
    "Thank you ‚Üí Gracias   \n",
    "Translate: How are you?    \n",
    "LLM's answer one:   \n",
    "¬øC√≥mo est√°s?   \n",
    "\n",
    "**Prompt two:**    \n",
    "Classify the sentiment:    \n",
    "Review: ‚ÄúI love the design and speed of this phone.‚Äù ‚Üí Positive    \n",
    "Review: ‚ÄúThe battery life is terrible.‚Äù ‚Üí Negative   \n",
    "Review: ‚ÄúIt‚Äôs okay, not the best.‚Äù ‚Üí Neutral    \n",
    "Review: ‚ÄúAbsolutely amazing performance!‚Äù ‚Üí    \n",
    "LLM's answer two:    \n",
    "Positive    \n",
    "\n",
    "**Prompt three:**    \n",
    "Correct the grammar:    \n",
    "\n",
    "‚ÄúShe go to school every day.‚Äù ‚Üí ‚ÄúShe goes to school every day.‚Äù    \n",
    "\n",
    "‚ÄúI has a dog.‚Äù ‚Üí ‚ÄúI have a dog.‚Äù    \n",
    "    \n",
    "‚ÄúHe don‚Äôt like pizza.‚Äù ‚Üí    \n",
    "LLM's answer three:    \n",
    "He doesn‚Äôt like pizza.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e3bbdb6-fff4-424c-a3d1-365c01cf932a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Same cases in Llama 4 maverick"
    }
   },
   "outputs": [],
   "source": [
    "prompt_one = \"\"\"\n",
    "Translate English to Spanish:\n",
    "\n",
    "Hello ‚Üí Hola\n",
    "\n",
    "Good night ‚Üí Buenas noches\n",
    "\n",
    "Thank you ‚Üí Gracias\n",
    "\n",
    "Translate: How are you?\"\"\"\n",
    "\n",
    "LLM_answer_one = chat_model.invoke(prompt_one)\n",
    "\n",
    "print(LLM_answer_one.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74199cdc-a4f5-41fd-8dad-b62bbaffadde",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Same cases in Llama 4 maverick"
    }
   },
   "outputs": [],
   "source": [
    "prompt_two = \"\"\"\n",
    "Classify the sentiment:\n",
    "Review: ‚ÄúI love the design and speed of this phone.‚Äù ‚Üí Positive\n",
    "Review: ‚ÄúThe battery life is terrible.‚Äù ‚Üí Negative\n",
    "Review: ‚ÄúIt‚Äôs okay, not the best.‚Äù ‚Üí Neutral\n",
    "Review: ‚ÄúAbsolutely amazing performance!‚Äù ‚Üí\n",
    "\"\"\"\n",
    "LLM_answer_two = chat_model.invoke(prompt_two)\n",
    "\n",
    "print(LLM_answer_two.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c16483f8-4c49-40ad-87eb-4bac1f877604",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Same cases in Llama 4 maverick"
    }
   },
   "outputs": [],
   "source": [
    "prompt_three = \"\"\"\n",
    "Correct the grammar:\n",
    "\n",
    "‚ÄúShe go to school every day.‚Äù ‚Üí ‚ÄúShe goes to school every day.‚Äù\n",
    "\n",
    "‚ÄúI has a dog.‚Äù ‚Üí ‚ÄúI have a dog.‚Äù\n",
    "\n",
    "‚ÄúHe don‚Äôt like pizza.‚Äù ‚Üí\n",
    "\"\"\"\n",
    "LLM_answer_three = chat_model.invoke(prompt_three)\n",
    "print(LLM_answer_three.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fe31ac7-8c77-4101-9d99-c52f4a29a2b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Prompting Chaining    \n",
    "**Bread tasks into subtasks**    \n",
    "Multi tasks are linked together, with the outupt of one prompt serving as the input of the next.   \n",
    "This method allows for more complex tasks to be broken down into manageable steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce2c37b9-a54b-4a44-b9a0-c4e86c88c8a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Examples generate by ChatGPT\n",
    "üîπ Example 1: Article Summarization + Title Generation    \n",
    "**Prompt one:**    \n",
    "Summarize the following article in 3 sentences:    \n",
    "\"Prompt engineering is a technique used to guide large language models. It involves crafting input queries to get desired output behavior. As LLMs become more capable, prompt engineering is turning into a vital skill for developers and researchers.\"    \n",
    "LLM's answer one:    \n",
    "Prompt engineering is a method for shaping the responses of large language models through carefully designed inputs. It helps guide the model toward producing desired results. With the growth of LLM capabilities, this skill is becoming increasingly important.    \n",
    "\n",
    "**Prompt two:**    \n",
    "Using the summary below, generate a compelling article title:    \n",
    "‚ÄúPrompt engineering is a method for shaping the responses of large language models through carefully designed inputs. It helps guide the model toward producing desired results. With the growth of LLM capabilities, this skill is becoming increasingly important.‚Äù    \n",
    "LLM's answer two:    \n",
    "‚ÄúThe Rise of Prompt Engineering: Shaping the Future of AI Interaction‚Äù    \n",
    "\n",
    "üîπ Example 2: Email to Bullet Points ‚Üí Slide Content    \n",
    "**Prompt one:**    \n",
    "Extract 5 key bullet points from this email:    \n",
    "\"Hi team, the product launch is scheduled for August 10th. We need marketing assets ready by August 5th. Sales training will happen the same week. Please confirm if all departments are aligned. Also, QA must finish testing by August 4th.\"    \n",
    "LLM's answer one:    \n",
    "\n",
    "Product launch date: August 10th    \n",
    "\n",
    "Marketing materials deadline: August 5th    \n",
    "\n",
    "Sales training scheduled for launch week    \n",
    "\n",
    "Request for departmental alignment    \n",
    "\n",
    "QA testing deadline: August 4th    \n",
    "\n",
    "**Prompt two:**    \n",
    "Turn the following bullet points into concise slide content for a launch planning presentation:    \n",
    "\n",
    "Product launch date: August 10th    \n",
    "\n",
    "Marketing materials deadline: August 5th    \n",
    "\n",
    "Sales training scheduled for launch week    \n",
    "\n",
    "Request for departmental alignment    \n",
    "\n",
    "QA testing deadline: August 4th    \n",
    "LLM's answer two:    \n",
    "Slide Title: Key Launch Deadlines    \n",
    "\n",
    "Launch: August 10    \n",
    "\n",
    "Marketing assets due: August 5    \n",
    "\n",
    "QA complete by: August 4    \n",
    "\n",
    "Sales training: Launch week    \n",
    "\n",
    "Cross-team alignment required    \n",
    "\n",
    "üîπ Example 3: Raw Idea ‚Üí Blog Outline ‚Üí Blog Introduction    \n",
    "**Prompt one:**    \n",
    "Turn this raw idea into a blog post outline:    \n",
    "\"How AI can support mental health and well-being in the workplace.\"    \n",
    "LLM's answer one:    \n",
    "Outline:    \n",
    "\n",
    "Introduction: The rising focus on mental health    \n",
    "    \n",
    "Challenges in workplace well-being    \n",
    "\n",
    "How AI tools can detect burnout or stress    \n",
    "\n",
    "Virtual assistants for emotional support    \n",
    "\n",
    "Ethical considerations and privacy    \n",
    "\n",
    "Conclusion: The future of AI in mental wellness    \n",
    "\n",
    "**Prompt two:**    \n",
    "Write an engaging introduction paragraph based on this outline:    \n",
    "\n",
    "Introduction: The rising focus on mental health        \n",
    "\n",
    "Challenges in workplace well-being    \n",
    "\n",
    "How AI tools can detect burnout or stress    \n",
    "\n",
    "Virtual assistants for emotional support    \n",
    "\n",
    "Ethical considerations and privacy    \n",
    "\n",
    "Conclusion: The future of AI in mental wellness    \n",
    "LLM's answer two:    \n",
    "In recent years, mental health has become a central topic in conversations about workplace wellness. With rising stress levels and burnout rates, organizations are seeking innovative ways to support employee well-being. One promising avenue is the use of AI-driven tools that not only monitor emotional health but also provide real-time assistance. As this technology advances, it holds great potential to transform how we approach mental health at work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ef6de4d-7b90-4b94-9ec8-1b56def2132a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Same cases in Llama 4 maverick"
    }
   },
   "outputs": [],
   "source": [
    "# Example 1\n",
    "prompt_one = \"\"\"\n",
    "Summarize the following article in 3 sentences:\n",
    "'Prompt engineering is a technique used to guide large language models. It involves crafting input queries to get desired output behavior. As LLMs become more capable, prompt engineering is turning into a vital skill for developers and researchers.'\"\"\"\n",
    "\n",
    "LLM_answer_one = chat_model.invoke(prompt_one)\n",
    "\n",
    "print(LLM_answer_one.content)\n",
    "\n",
    "prompt_two = f\"\"\"Using the summary below, generate a compelling article title:\n",
    "{LLM_answer_one.content}\"\"\"\n",
    "\n",
    "\n",
    "LLM_answer_two = chat_model.invoke(prompt_two)\n",
    "\n",
    "print(LLM_answer_two.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d59edd04-866c-4807-9379-c7b2f29466a3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Same cases in Llama 4 maverick"
    }
   },
   "outputs": [],
   "source": [
    "# Example 2\n",
    "prompt_one = \"\"\"Extract 5 key bullet points from this email:\n",
    "'Hi team, the product launch is scheduled for August 10th. We need marketing assets ready by August 5th. Sales training will happen the same week. Please confirm if all departments are aligned. Also, QA must finish testing by August 4th.'\"\"\"\n",
    "\n",
    "LLM_answer_one = chat_model.invoke(prompt_one)\n",
    "\n",
    "print(LLM_answer_one.content)\n",
    "\n",
    "prompt_two = f\"\"\"Turn the following bullet points into concise slide content for a launch planning presentation:\n",
    "{LLM_answer_one.content}\"\"\"\n",
    "\n",
    "\n",
    "LLM_answer_two = chat_model.invoke(prompt_two)\n",
    "\n",
    "print(LLM_answer_two.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4907c9c7-b734-4227-820d-a581dba0cf25",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Same cases in Llama 4 maverick"
    }
   },
   "outputs": [],
   "source": [
    "# Example 3\n",
    "prompt_one = \"\"\"Turn this raw idea into a blog post outline:\n",
    "'How AI can support mental health and well-being in the workplace.'\"\"\"\n",
    "\n",
    "LLM_answer_one = chat_model.invoke(prompt_one)\n",
    "\n",
    "print(LLM_answer_one.content)\n",
    "\n",
    "prompt_two = f\"\"\"Write an engaging introduction paragraph based on this outline:\n",
    "{LLM_answer_one.content}\"\"\"\n",
    "\n",
    "\n",
    "LLM_answer_two = chat_model.invoke(prompt_two)\n",
    "\n",
    "print(LLM_answer_two.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82ccfda4-2e0d-46ee-a922-69fd2cf4906d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Chain-of-Thought Prompoting    \n",
    "**Let's think step-by-step**   \n",
    "CoT prompting enhaces the reasoning capabilities of LLMs by guiding them to articulare their thought process step-by-step, similar to human reasoning.  \n",
    "Researsh in this area has mixed findings. So, the CoT prompt not always works as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1bc53f7d-c075-435a-8e3b-a609366ba973",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Examples generated by ChatGPT\n",
    "**Prompt one:**   \n",
    "If there are 12 cookies and 4 kids, how many cookies does each kid get?      \n",
    "LLM's answer one:   \n",
    "There are 12 cookies and 4 kids. Dividing 12 by 4 gives 3. So each kid gets 3 cookies.   \n",
    "\n",
    "**Prompt two:**   \n",
    "Tom is twice as old as Sarah. Sarah is 10 years old. How old is Tom?   \n",
    "LLM's answer two:   \n",
    "Sarah is 10. Tom is twice as old, so 10 √ó 2 = 20. Tom is 20 years old.   \n",
    "\n",
    "**Prompt three:**   \n",
    "John had 15 apples. He gave 3 to his friend and then bought 5 more. How many apples does he have now?   \n",
    "LLM's answer three:   \n",
    "John had 15 apples. He gave away 3, so now he has 12. Then he bought 5 more, so 12 + 5 = 17. He has 17 apples.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6430a82-4df5-4da9-9435-6587b4ef630e",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Same cases in Llama 4 maverick"
    }
   },
   "outputs": [],
   "source": [
    "prompt_one = \"\"\"If there are 12 cookies and 4 kids, how many cookies does each kid get??\n",
    "Let's thing step-by-step\"\"\"\n",
    "\n",
    "LLM_answer_one = chat_model.invoke(prompt_one)\n",
    "\n",
    "print(LLM_answer_one.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b045ec9-a350-4148-9f74-a2666978e66f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Same cases in Llama 4 maverick"
    }
   },
   "outputs": [],
   "source": [
    "prompt_two = \"\"\"Tom is twice as old as Sarah. Sarah is 10 years old. How old is Tom?Let's thing step-by-step\"\"\"\n",
    "LLM_answer_two = chat_model.invoke(prompt_two)\n",
    "\n",
    "print(LLM_answer_two.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0af7cd0a-f5da-46ef-af34-bf0983279290",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Same cases in Llama 4 maverick"
    }
   },
   "outputs": [],
   "source": [
    "prompt_three = \"\"\"John had 15 apples. He gave 3 to his friend and then bought 5 more. How many apples does he have now?Let's thing step-by-step\"\"\"\n",
    "LLM_answer_three = chat_model.invoke(prompt_three)\n",
    "print(LLM_answer_three.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "93f6df1f-7ab4-419f-aed7-117349678f66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Instruction prompting (a.k.a. instruction tuning)\n",
    "* Give explicit, clear instructions on what you want the model to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc557597-091f-4a08-8979-2b71516573e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Example genereated by ChatGPT\n",
    "**Prompt one:**    \n",
    "Write a short paragraph (3‚Äì4 sentences) describing the importance of sleep for teenagers.    \n",
    "LLM's answer one:    \n",
    "Sleep is essential for teenagers because it supports growth and development. It also improves concentration and memory. Without enough rest, teens may struggle in school and experience mood swings. Adequate sleep contributes to both physical and mental health.    \n",
    "\n",
    "**Prompt two:**    \n",
    "List three benefits of using solar energy.    \n",
    "LLM's answer two:    \n",
    "\n",
    "It reduces electricity bills.    \n",
    "\n",
    "It‚Äôs a clean and renewable energy source.    \n",
    "\n",
    "It lowers carbon emissions.    \n",
    "\n",
    "**Prompt three:**    \n",
    "Explain in simple terms how a computer virus works.    \n",
    "LLM's answer three:    \n",
    "A computer virus is a program that spreads from one computer to another, just like a real virus. It can damage files, steal information, or make your computer act strangely. Viruses often hide inside other programs or files and activate when opened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1512c101-520c-4874-b5cc-04701ecdd31f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Same cases in Llama 4 maverick"
    }
   },
   "outputs": [],
   "source": [
    "prompt_one = \"\"\"Write a short paragraph (3‚Äì4 sentences) describing the importance of sleep for teenagers.\"\"\"\n",
    "\n",
    "LLM_answer_one = chat_model.invoke(prompt_one)\n",
    "\n",
    "print(LLM_answer_one.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61edca88-d7fd-4a3b-83bd-768e0122a3d5",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Same cases in Llama 4 maverick"
    }
   },
   "outputs": [],
   "source": [
    "prompt_two = \"\"\"List three benefits of using solar energy.\"\"\"\n",
    "LLM_answer_two = chat_model.invoke(prompt_two)\n",
    "\n",
    "print(LLM_answer_two.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b25b3499-42dc-48c6-9aed-7c699f239364",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Same cases in Llama 4 maverick"
    }
   },
   "outputs": [],
   "source": [
    "prompt_three = \"\"\"Explain in simple terms how a computer virus works.\"\"\"\n",
    "LLM_answer_three = chat_model.invoke(prompt_three)\n",
    "print(LLM_answer_three.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "266a682f-5fab-4b25-8c79-2b38835440c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 5. Role prompting (a.k.a. persona prompting)\n",
    "* Ask the model to play a specific role or persona before answering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89766dc3-44e2-4b3b-8a6d-5a3f5702a10b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Examples generated by ChatGPT\n",
    "P**rompt one:**    \n",
    "You are a friendly science teacher. Explain gravity to a 10-year-old.    \n",
    "LLM's answer one:    \n",
    "Sure! Gravity is like an invisible force that pulls things toward the ground. It's the reason why we don‚Äôt float away and why things fall when you drop them. The Earth pulls everything toward it‚Äîjust like a magnet!    \n",
    "\n",
    "**Prompt two:**    \n",
    "You are a professional fitness coach. Give three tips for staying active while working an office job.    \n",
    "LLM's answer two:    \n",
    "\n",
    "Take short standing or walking breaks every hour.    \n",
    "\n",
    "Use a standing desk if possible.    \n",
    "\n",
    "Do quick desk exercises like leg raises or stretches.    \n",
    "\n",
    "**Prompt three:**    \n",
    "You are a historian. Briefly explain the cause of World War I.    \n",
    "LLM's answer three:    \n",
    "World War I began due to a mix of political tensions, alliances, and militarism in Europe. The immediate cause was the assassination of Archduke Franz Ferdinand of Austria-Hungary in 1914. This event triggered a chain reaction of declarations of war between major powers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62d5af95-cdc1-4c78-bbbc-d461d06ecacd",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Same cases in Llama 4 maverick"
    }
   },
   "outputs": [],
   "source": [
    "prompt_one = \"\"\"You are a friendly science teacher. Explain gravity to a 10-year-old.\"\"\"\n",
    "\n",
    "LLM_answer_one = chat_model.invoke(prompt_one)\n",
    "\n",
    "print(LLM_answer_one.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebcbf348-3e76-4277-84a8-272e3ec6dd35",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Same cases in Llama 4 maverick"
    }
   },
   "outputs": [],
   "source": [
    "prompt_two = \"\"\"You are a professional fitness coach. Give three tips for staying active while working an office job.\"\"\"\n",
    "LLM_answer_two = chat_model.invoke(prompt_two)\n",
    "\n",
    "print(LLM_answer_two.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d950a674-2f62-4259-bf0b-95bb7279f949",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Same cases in Llama 4 maverick"
    }
   },
   "outputs": [],
   "source": [
    "prompt_three = \"\"\"You are a historian. Briefly explain the cause of World War I.\"\"\"\n",
    "LLM_answer_three = chat_model.invoke(prompt_three)\n",
    "print(LLM_answer_three.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0772074a-3d58-4d0d-9465-e7cf895aaa4e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Tip: Formata prompts \n",
    "* Use dilimiters to distinguish between instruction and context   \n",
    "  * Pound sign #####    \n",
    "  * Backticks `````\n",
    "  * Braces / brackets [] / {}    \n",
    "  * Dashes -----\n",
    "*Ask the model to return structured output\n",
    "  * HTML, json, markdown, tec...   \n",
    "* Provide a correct example\n",
    "  * return your answer in the python dict format like {'some key':'some value'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f94c8e2-c604-4282-bc2c-0c54dc8993e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Tip: Guide the model for better responses\n",
    "* Ask the model not to make things up / Hallucinate\n",
    "* Ask the model not to assume ro probe for sensitive information\n",
    "* Ask the model not rush to a solution (think step-by-step)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "prompts_engineering",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
