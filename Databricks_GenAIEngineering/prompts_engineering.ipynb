{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "426a2e29-b971-4e0b-8069-3e07a46ce056",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install necessary libraries"
    }
   },
   "outputs": [],
   "source": [
    "%pip install mlflow==2.10.1 lxml==4.9.3 langchain==0.1.5 databricks-vectorsearch==0.22 cloudpickle==2.2.1 databricks-sdk==0.18.0 cloudpickle==2.2.1 pydantic==2.5.2 openpyxl\n",
    "%pip install pip mlflow[databricks]==2.10.1\n",
    "\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a22e6910-7c1d-41ca-9274-749791f1be7a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Imports"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import Window\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import io\n",
    "import plotly.express as px\n",
    "from langchain_community.chat_models import ChatDatabricks\n",
    "\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0fdf206d-8ffd-4cf8-979a-c00edb2f956b",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Instaciate a chatbot (llama)"
    }
   },
   "outputs": [],
   "source": [
    "chat_endpoint = \"databricks-llama-4-maverick\" \n",
    "chat_model = ChatDatabricks(endpoint = chat_endpoint,\n",
    "                            temperature = 0,\n",
    "                            max_tokens = 8096) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7fcc22fe-0234-4226-80fe-5d77e7761227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Prompt Engineering    \n",
    "**Definitions**    \n",
    "  * **Prompt:** is an input or query given to a LLM to elict to a specific response or output        \n",
    "  * **Prompt Engineering:** is the pratice of designing and refining prompts to optimize the responses generated by AI models.  \n",
    "\n",
    "A good prompt usually consist of:    \n",
    "  * Instruction    \n",
    "  * Context    \n",
    "  * input / question    \n",
    "  * Output type / format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcd58b48-551d-44f7-a956-8c740f649624",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 1.  Zero-shot Prompting.   \n",
    "Prompt for a generation of content, text, video, image etc... without providing any examples or additional training specific task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fef47ff0-61f1-461f-a83b-687346619622",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d6b9046-276d-4f34-a8bc-1303294b32e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### 2. Few-shot Prompting.    \n",
    "Prompt provides with a few input-ouput examples to guide the model for generating the desired outuput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9e3bbdb6-fff4-424c-a3d1-365c01cf932a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9fe31ac7-8c77-4101-9d99-c52f4a29a2b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Prompting Chaining    \n",
    "**Bread tasks into subtasks**    \n",
    "Multi tasks are linked together, with the outupt of one prompt serving as the input of the next.   \n",
    "This method allows for more complex tasks to be broken down into manageable steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "383dc101-a7ab-4637-8f56-6fd86e985eb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82ccfda4-2e0d-46ee-a922-69fd2cf4906d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Chain-of-Thought Prompoting    \n",
    "**Let's think step-by-step**   \n",
    "CoT prompting enhaces the reasoning capabilities of LLMs by guiding them to articulare their thought process step-by-step, similar to human reasoning.  \n",
    "Researsh in this area has mixed findings. So, the CoT prompt not always works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d11c9bac-587e-4e38-9005-ca5c5937154e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "prompts_engineering",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
